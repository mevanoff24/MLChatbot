{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "MODEL_PATH = Path('models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Approaches\n",
    "- Doc2Vec : you can train your dataset using Doc2Vec and then use the sentence vectors.\n",
    "- Average of Word2Vec vectors : You can just take the average of all the word vectors in a sentence. This average vector will represent your sentence vector.\n",
    "- Average of Word2Vec vectors with TF-IDF : this is one of the best approach which I will recommend. Just take the word vectors and multiply it with their TF-IDF scores. Just take the average and it will represent your sentence vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_vectors(question, embeddings, dim):\n",
    "    words_embedding = [embeddings[word] for word in question.lower().split() if word in embeddings]\n",
    "    if not words_embedding:\n",
    "        return np.zeros(dim)\n",
    "    words_embedding = np.array(words_embedding).astype(np.float32)\n",
    "    return words_embedding.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(X, X_test=None, save_path=MODEL_PATH/'tf_idf.pkl'):\n",
    "    vect = TfidfVectorizer(token_pattern='(\\S+)', min_df=2, max_df=0.9, ngram_range=(1,1))\n",
    "    vect.fit(X)\n",
    "    # save vect\n",
    "    with open(save_path, mode='wb') as f:\n",
    "        pickle.dump(vect, f)\n",
    "        \n",
    "    X = vect.transform(X)\n",
    "    if X_test: \n",
    "        X_test = vect.transform(X_test)\n",
    "        return X, X_test   \n",
    "    return X, vect\n",
    "\n",
    "# X, vect = compute_tfidf(data)\n",
    "# idf_scores = defaultdict(lambda:0, zip(vect.get_feature_names(), vect.idf_))\n",
    "\n",
    "def average_tfidf_vectors(question, embeddings, dim, vect):\n",
    "    # if blank question \n",
    "    if not question:\n",
    "        return np.zeros(dim).astype(np.float32)\n",
    "    \n",
    "    # get idf weights\n",
    "    split_question = question.lower().split()\n",
    "    words_embedding = np.zeros((dim, len(split_question))).astype(np.float32)\n",
    "    for i, token in enumerate(split_question):\n",
    "        if token in embeddings:\n",
    "            embed_score = embeddings[token]\n",
    "        else: embed_score = 0\n",
    "        idf_score = idf_scores[token]\n",
    "        # word vectors multiply by their TF-IDF scores\n",
    "        words_embedding[:, i] = embed_score * idf_score\n",
    "    \n",
    "    return words_embedding.mean(axis=1)\n",
    "\n",
    "\n",
    "# question = 'How do I use with WPF bindings dfhfohsodfhokhv what are the different use cases'\n",
    "# question = ''\n",
    "# average_tfidf_vectors(question, embeddings, 300, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self):\n",
    "        self.data = all_text\n",
    "    def __iter__(self):\n",
    "        for i, line in enumerate(self.data):\n",
    "            yield TaggedDocument(words=line.split(), tags=['SENT_{}'.format(i)])\n",
    "\n",
    "\n",
    "\n",
    "labeled_sent = LabeledLineSentence()\n",
    "# print(next(iter(labeled_sent)))\n",
    "model = Doc2Vec(vector_size=300, window=10, min_count=1, workers=4, alpha=0.025, min_alpha=0.025, epochs=10) \n",
    "model.build_vocab(labeled_sent)\n",
    "model.train(labeled_sent, total_examples=model.corpus_count, epochs=model.epochs, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH/'doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['I', 'want', 'to', 'use', 'a', 'track', 'bar', 'to', 'change', 'a', 'form', 's', 'opacity', 'This', 'is', 'my', 'code', 'When', 'I', 'build', 'the', 'application', 'it', 'gives', 'the', 'following', 'error', 'Cannot', 'implicitly', 'convert', 'type', 'to', 'I', 'tried', 'using', 'and', 'but', 'then', 'the', 'control', 'doesn', 't', 'work', 'This', 'code', 'worked', 'fine', 'in', 'a', 'past', 'VB', 'NET', 'project'], tags=['SENT_0'])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labeled_sent)[:1]\n",
    "# model.wv.most_similar([labeled_sent][0])\n",
    "\n",
    "model.infer_vector(labeled_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word ' ' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0a16ca7b6bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model.infer_vector(ex.split())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar_to_given\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar_to_given\u001b[0;34m(self, entity1, entities_list)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar_to_given\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;34m\"\"\"Return the entity from entities_list most similar to entity1.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mentities_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcloser_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar_to_given\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;34m\"\"\"Return the entity from entities_list most similar to entity1.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mentities_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcloser_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \"\"\"\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word ' ' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "ex = 'Given a representing a person s birthday how do I calculate their age in years'\n",
    "\n",
    "# model.infer_vector(ex.split())\n",
    "model.wv.most_similar_to_given(ex.split(), all_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'I': 8405,\n",
       "         'want': 665,\n",
       "         'to': 6625,\n",
       "         'use': 711,\n",
       "         'a': 5227,\n",
       "         'track': 15,\n",
       "         'bar': 18,\n",
       "         'change': 127,\n",
       "         'form': 79,\n",
       "         's': 1051,\n",
       "         'opacity': 6,\n",
       "         'This': 301,\n",
       "         'is': 2836,\n",
       "         'my': 1188,\n",
       "         'code': 565,\n",
       "         'When': 198,\n",
       "         'build': 53,\n",
       "         'the': 8297,\n",
       "         'application': 170,\n",
       "         'it': 2132,\n",
       "         'gives': 39,\n",
       "         'following': 256,\n",
       "         'error': 237,\n",
       "         'Cannot': 9,\n",
       "         'implicitly': 2,\n",
       "         'convert': 75,\n",
       "         'type': 119,\n",
       "         'tried': 194,\n",
       "         'using': 623,\n",
       "         'and': 3777,\n",
       "         'but': 1082,\n",
       "         'then': 226,\n",
       "         'control': 32,\n",
       "         'doesn': 178,\n",
       "         't': 947,\n",
       "         'work': 338,\n",
       "         'worked': 37,\n",
       "         'fine': 55,\n",
       "         'in': 3032,\n",
       "         'past': 40,\n",
       "         'VB': 1,\n",
       "         'NET': 59,\n",
       "         'project': 129,\n",
       "         'Given': 27,\n",
       "         'representing': 8,\n",
       "         'person': 12,\n",
       "         'birthday': 1,\n",
       "         'how': 516,\n",
       "         'do': 1293,\n",
       "         'calculate': 10,\n",
       "         'their': 111,\n",
       "         'age': 4,\n",
       "         'years': 103,\n",
       "         'specific': 96,\n",
       "         'value': 211,\n",
       "         'display': 44,\n",
       "         'relative': 18,\n",
       "         'time': 360,\n",
       "         'like': 911,\n",
       "         '2': 284,\n",
       "         'hours': 37,\n",
       "         'ago': 29,\n",
       "         '3': 200,\n",
       "         'days': 56,\n",
       "         'month': 3,\n",
       "         'Is': 536,\n",
       "         'there': 805,\n",
       "         'any': 388,\n",
       "         'standard': 61,\n",
       "         'way': 664,\n",
       "         'for': 1569,\n",
       "         'Web': 20,\n",
       "         'Server': 35,\n",
       "         'be': 1295,\n",
       "         'able': 127,\n",
       "         'determine': 27,\n",
       "         'user': 153,\n",
       "         'timezone': 18,\n",
       "         'within': 63,\n",
       "         'web': 100,\n",
       "         'page': 143,\n",
       "         'Perhaps': 10,\n",
       "         'from': 777,\n",
       "         'an': 999,\n",
       "         'HTTP': 37,\n",
       "         'header': 37,\n",
       "         'or': 858,\n",
       "         'part': 64,\n",
       "         'of': 2979,\n",
       "         'agent': 6,\n",
       "         'string': 272,\n",
       "         'often': 74,\n",
       "         'have': 1476,\n",
       "         'sort': 47,\n",
       "         'dictionary': 26,\n",
       "         'consisting': 2,\n",
       "         'keys': 27,\n",
       "         'values': 130,\n",
       "         'by': 572,\n",
       "         'For': 199,\n",
       "         'example': 302,\n",
       "         'hash': 20,\n",
       "         'words': 29,\n",
       "         'respective': 3,\n",
       "         'frequencies': 1,\n",
       "         'that': 2225,\n",
       "         'order': 72,\n",
       "         'frequency': 4,\n",
       "         'There': 90,\n",
       "         'which': 509,\n",
       "         'good': 214,\n",
       "         'single': 77,\n",
       "         'say': 101,\n",
       "         'map': 17,\n",
       "         'back': 119,\n",
       "         'word': 27,\n",
       "         'SortedDictionary': 1,\n",
       "         'orders': 4,\n",
       "         'key': 91,\n",
       "         'not': 1001,\n",
       "         'Some': 48,\n",
       "         'resort': 4,\n",
       "         'custom': 36,\n",
       "         'class': 234,\n",
       "         'cleaner': 6,\n",
       "         'Form': 7,\n",
       "         'based': 82,\n",
       "         'authentication': 9,\n",
       "         'websites': 7,\n",
       "         'We': 66,\n",
       "         'believe': 54,\n",
       "         'Stack': 196,\n",
       "         'Overflow': 172,\n",
       "         'should': 355,\n",
       "         'just': 364,\n",
       "         'resource': 38,\n",
       "         'very': 184,\n",
       "         'technical': 12,\n",
       "         'questions': 248,\n",
       "         'also': 272,\n",
       "         'general': 46,\n",
       "         'guidelines': 6,\n",
       "         'on': 1389,\n",
       "         'solve': 40,\n",
       "         'variations': 2,\n",
       "         'common': 38,\n",
       "         'problems': 43,\n",
       "         'topic': 17,\n",
       "         'such': 130,\n",
       "         'experiment': 4,\n",
       "         'It': 244,\n",
       "         'include': 93,\n",
       "         'topics': 6,\n",
       "         'as': 970,\n",
       "         'How': 781,\n",
       "         'log': 56,\n",
       "         'out': 318,\n",
       "         'remain': 14,\n",
       "         'logged': 6,\n",
       "         'Managing': 1,\n",
       "         'cookies': 4,\n",
       "         'including': 25,\n",
       "         'recommended': 16,\n",
       "         'settings': 15,\n",
       "         'SSL': 9,\n",
       "         'HTTPS': 5,\n",
       "         'encryption': 5,\n",
       "         'store': 38,\n",
       "         'passwords': 13,\n",
       "         'Using': 53,\n",
       "         'secret': 1,\n",
       "         'Forgotten': 1,\n",
       "         'username': 11,\n",
       "         'password': 28,\n",
       "         'functionality': 36,\n",
       "         'Use': 24,\n",
       "         'nonces': 1,\n",
       "         'prevent': 18,\n",
       "         'cross': 20,\n",
       "         'site': 205,\n",
       "         'request': 70,\n",
       "         'forgeries': 1,\n",
       "         'CSRF': 1,\n",
       "         'OpenID': 2,\n",
       "         'Remember': 3,\n",
       "         'me': 478,\n",
       "         'checkbox': 13,\n",
       "         'Browser': 2,\n",
       "         'autocompletion': 1,\n",
       "         'usernames': 1,\n",
       "         'Secret': 1,\n",
       "         'URLs': 14,\n",
       "         'public': 137,\n",
       "         'URL': 67,\n",
       "         'protected': 7,\n",
       "         'digest': 2,\n",
       "         'Checking': 4,\n",
       "         'strength': 2,\n",
       "         'E': 12,\n",
       "         'mail': 7,\n",
       "         'validation': 8,\n",
       "         'much': 127,\n",
       "         'more': 380,\n",
       "         'about': 335,\n",
       "         'things': 95,\n",
       "         'Roles': 1,\n",
       "         'authorization': 3,\n",
       "         'basic': 30,\n",
       "         'Please': 37,\n",
       "         'help': 172,\n",
       "         'us': 37,\n",
       "         'Suggesting': 1,\n",
       "         'subtopics': 1,\n",
       "         'Submitting': 1,\n",
       "         'articles': 11,\n",
       "         'this': 1757,\n",
       "         'subject': 15,\n",
       "         'Editing': 1,\n",
       "         'official': 22,\n",
       "         'answer': 141,\n",
       "         'One': 37,\n",
       "         'may': 109,\n",
       "         'always': 154,\n",
       "         'know': 405,\n",
       "         'Type': 21,\n",
       "         'object': 212,\n",
       "         'at': 375,\n",
       "         'compile': 37,\n",
       "         'need': 357,\n",
       "         'create': 159,\n",
       "         'instance': 62,\n",
       "         'you': 751,\n",
       "         'get': 496,\n",
       "         'new': 412,\n",
       "         'so': 527,\n",
       "         'important': 39,\n",
       "         'your': 243,\n",
       "         'data': 251,\n",
       "         'set': 229,\n",
       "         'increases': 4,\n",
       "         'size': 54,\n",
       "         'can': 1224,\n",
       "         'someone': 99,\n",
       "         'explain': 65,\n",
       "         'does': 340,\n",
       "         'indexing': 7,\n",
       "         'level': 37,\n",
       "         'information': 64,\n",
       "         'queries': 20,\n",
       "         'index': 56,\n",
       "         'field': 62,\n",
       "         'check': 102,\n",
       "         'database': 108,\n",
       "         'column': 64,\n",
       "         'Yes': 11,\n",
       "         'Podcasts': 3,\n",
       "         'those': 128,\n",
       "         'nice': 39,\n",
       "         'little': 51,\n",
       "         'Audiobooks': 1,\n",
       "         'listen': 5,\n",
       "         'With': 32,\n",
       "         'current': 137,\n",
       "         'amount': 21,\n",
       "         'searching': 14,\n",
       "         'needle': 1,\n",
       "         'haystack': 2,\n",
       "         'except': 20,\n",
       "         'happens': 31,\n",
       "         'Internet': 33,\n",
       "         'filled': 5,\n",
       "         'with': 1294,\n",
       "         'too': 98,\n",
       "         'many': 120,\n",
       "         'these': 188,\n",
       "         'Hot': 3,\n",
       "         'Gadgets': 1,\n",
       "         'stuff': 35,\n",
       "         'Now': 94,\n",
       "         'even': 156,\n",
       "         'though': 59,\n",
       "         'am': 483,\n",
       "         'mainly': 12,\n",
       "         'developer': 43,\n",
       "         'nowadays': 3,\n",
       "         'maybe': 30,\n",
       "         'anyone': 84,\n",
       "         'knows': 17,\n",
       "         'some': 502,\n",
       "         'people': 121,\n",
       "         'regarding': 23,\n",
       "         'whole': 44,\n",
       "         'software': 26,\n",
       "         'lifecycle': 4,\n",
       "         'Unit': 5,\n",
       "         'Testing': 3,\n",
       "         'Continous': 1,\n",
       "         'Integration': 3,\n",
       "         'Documentation': 1,\n",
       "         'Deployment': 1,\n",
       "         'So': 188,\n",
       "         'what': 575,\n",
       "         'are': 794,\n",
       "         'guys': 6,\n",
       "         'gals': 1,\n",
       "         'listening': 5,\n",
       "         'note': 24,\n",
       "         'categorizations': 1,\n",
       "         'somewhat': 12,\n",
       "         'subjective': 4,\n",
       "         '100': 44,\n",
       "         'accurate': 12,\n",
       "         'podcasts': 2,\n",
       "         'cover': 10,\n",
       "         'several': 84,\n",
       "         'areas': 10,\n",
       "         'Categorization': 1,\n",
       "         'made': 95,\n",
       "         'against': 17,\n",
       "         'considered': 18,\n",
       "         'main': 81,\n",
       "         'area': 21,\n",
       "         'General': 9,\n",
       "         'Software': 8,\n",
       "         'Engineering': 3,\n",
       "         'Productivity': 1,\n",
       "         'inactive': 4,\n",
       "         'still': 143,\n",
       "         'TekPub': 1,\n",
       "         'Requires': 2,\n",
       "         'Paid': 1,\n",
       "         'Subscription': 1,\n",
       "         'Radio': 6,\n",
       "         '43': 6,\n",
       "         'Folders': 1,\n",
       "         'Perspectives': 1,\n",
       "         'Dr': 1,\n",
       "         'Dobb': 1,\n",
       "         'now': 201,\n",
       "         'video': 13,\n",
       "         'feed': 6,\n",
       "         'The': 553,\n",
       "         'Pragmatic': 2,\n",
       "         'Podcast': 15,\n",
       "         'Inactive': 4,\n",
       "         'IT': 6,\n",
       "         'Matters': 1,\n",
       "         'Agile': 1,\n",
       "         'Toolkit': 2,\n",
       "         'Trace': 1,\n",
       "         'Parleys': 1,\n",
       "         'Techzing': 1,\n",
       "         'Startup': 1,\n",
       "         'Success': 2,\n",
       "         'Berkeley': 2,\n",
       "         'CS': 3,\n",
       "         'lectures': 4,\n",
       "         'FLOSS': 1,\n",
       "         'Weekly': 3,\n",
       "         'Developer': 12,\n",
       "         'Life': 1,\n",
       "         'Visual': 51,\n",
       "         'Studio': 61,\n",
       "         'Microsoft': 18,\n",
       "         'Herding': 1,\n",
       "         'Code': 26,\n",
       "         'Hanselminutes': 1,\n",
       "         'Rocks': 1,\n",
       "         'Deep': 2,\n",
       "         'Fried': 1,\n",
       "         'Bytes': 1,\n",
       "         'Alt': 5,\n",
       "         'Net': 5,\n",
       "         'Polymorphic': 1,\n",
       "         'inconsistent': 3,\n",
       "         'Sparkling': 1,\n",
       "         'Client': 1,\n",
       "         'Silverlight': 1,\n",
       "         'dnrTV': 1,\n",
       "         'Spaghetti': 1,\n",
       "         'ASP': 24,\n",
       "         'Channel': 4,\n",
       "         '9': 41,\n",
       "         'TFS': 5,\n",
       "         'PowerScripting': 1,\n",
       "         'Thirsty': 1,\n",
       "         'Elegant': 1,\n",
       "         'ConnectedShow': 1,\n",
       "         'Crafty': 1,\n",
       "         'Coders': 2,\n",
       "         'Coding': 2,\n",
       "         'QA': 2,\n",
       "         'jQuery': 151,\n",
       "         'yayQuery': 1,\n",
       "         'podcast': 6,\n",
       "         'Java': 169,\n",
       "         'Groovy': 4,\n",
       "         'Posse': 1,\n",
       "         'Grails': 4,\n",
       "         'Technology': 2,\n",
       "         'Insider': 1,\n",
       "         'Basement': 1,\n",
       "         'Ruby': 39,\n",
       "         'Rails': 16,\n",
       "         'Railscasts': 1,\n",
       "         'Envy': 1,\n",
       "         'Rubiverse': 1,\n",
       "         'Ruby5': 1,\n",
       "         'Design': 8,\n",
       "         'JavaScript': 279,\n",
       "         'Ajax': 21,\n",
       "         'WebDevRadio': 1,\n",
       "         'Boagworld': 1,\n",
       "         'Rissington': 1,\n",
       "         'Ajaxian': 1,\n",
       "         'YUI': 2,\n",
       "         'Theater': 1,\n",
       "         'Unix': 14,\n",
       "         'Linux': 46,\n",
       "         'Mac': 21,\n",
       "         'iPhone': 17,\n",
       "         'Network': 5,\n",
       "         'Hacker': 2,\n",
       "         'Public': 3,\n",
       "         'Outlaws': 1,\n",
       "         'OS': 47,\n",
       "         'Ken': 1,\n",
       "         'LugRadio': 1,\n",
       "         'radio': 6,\n",
       "         'show': 63,\n",
       "         'Action': 4,\n",
       "         'Show': 5,\n",
       "         'Kernel': 2,\n",
       "         'Mailing': 1,\n",
       "         'List': 61,\n",
       "         'LKML': 1,\n",
       "         'Summary': 6,\n",
       "         'Stanford': 1,\n",
       "         'programming': 74,\n",
       "         'Advanced': 1,\n",
       "         'Development': 7,\n",
       "         'Course': 2,\n",
       "         'Madison': 1,\n",
       "         'Area': 3,\n",
       "         'Technical': 5,\n",
       "         'College': 1,\n",
       "         'WWDC': 1,\n",
       "         '2010': 16,\n",
       "         'Session': 1,\n",
       "         'Videos': 1,\n",
       "         'requires': 29,\n",
       "         'Apple': 7,\n",
       "         'registration': 1,\n",
       "         'System': 38,\n",
       "         'Administration': 1,\n",
       "         'Security': 7,\n",
       "         'Infrastructure': 1,\n",
       "         'RunAs': 1,\n",
       "         'Crypto': 1,\n",
       "         'Gram': 1,\n",
       "         'Hak5': 1,\n",
       "         'VMWare': 2,\n",
       "         'VMTN': 1,\n",
       "         'Windows': 84,\n",
       "         'PaulDotCom': 1,\n",
       "         'Register': 2,\n",
       "         'Semi': 1,\n",
       "         'Coherent': 1,\n",
       "         'Computing': 1,\n",
       "         'FeatherCast': 1,\n",
       "         'Tech': 3,\n",
       "         'Business': 1,\n",
       "         'Tekzilla': 1,\n",
       "         'Week': 1,\n",
       "         'Guardian': 1,\n",
       "         'PCMag': 1,\n",
       "         'Entrepreneurship': 1,\n",
       "         'Corner': 1,\n",
       "         'Manager': 11,\n",
       "         'Tools': 5,\n",
       "         'Other': 17,\n",
       "         'Misc': 1,\n",
       "         'Networks': 1,\n",
       "         'Conversations': 1,\n",
       "         'Retrobits': 1,\n",
       "         'No': 32,\n",
       "         'Agenda': 1,\n",
       "         'Netcast': 1,\n",
       "         'Cranky': 1,\n",
       "         'Geeks': 1,\n",
       "         'Command': 6,\n",
       "         'Line': 9,\n",
       "         'Freelance': 1,\n",
       "         'IBM': 2,\n",
       "         'developerWorks': 1,\n",
       "         'Open': 7,\n",
       "         'Season': 1,\n",
       "         'Drunk': 1,\n",
       "         'Retired': 1,\n",
       "         'Technometria': 1,\n",
       "         'Sod': 1,\n",
       "         'Radio4Nerds': 1,\n",
       "         'Medley': 1,\n",
       "         'Preferred': 1,\n",
       "         'languages': 33,\n",
       "         'C': 353,\n",
       "         'looking': 129,\n",
       "         'helpful': 62,\n",
       "         'books': 9,\n",
       "         'tutorials': 7,\n",
       "         'write': 93,\n",
       "         'own': 66,\n",
       "         'compiler': 41,\n",
       "         'simply': 58,\n",
       "         'educational': 3,\n",
       "         'purposes': 6,\n",
       "         'most': 159,\n",
       "         'familiar': 19,\n",
       "         'prefer': 33,\n",
       "         'resources': 20,\n",
       "         'involve': 5,\n",
       "         'one': 556,\n",
       "         'three': 52,\n",
       "         'acceptable': 9,\n",
       "         'If': 257,\n",
       "         'could': 196,\n",
       "         'go': 85,\n",
       "         'tell': 55,\n",
       "         'yourself': 8,\n",
       "         'read': 134,\n",
       "         'book': 25,\n",
       "         'beginning': 17,\n",
       "         'career': 9,\n",
       "         'would': 639,\n",
       "         'expect': 21,\n",
       "         'list': 203,\n",
       "         'varied': 1,\n",
       "         'wide': 16,\n",
       "         'range': 28,\n",
       "         'To': 58,\n",
       "         'search': 42,\n",
       "         'box': 32,\n",
       "         'upper': 6,\n",
       "         'right': 128,\n",
       "         'corner': 7,\n",
       "         'answers': 217,\n",
       "         'question': 237,\n",
       "         'branch': 284,\n",
       "         'SVN': 20,\n",
       "         'beyond': 7,\n",
       "         'RAD': 1,\n",
       "         'drag': 4,\n",
       "         'drop': 17,\n",
       "         'configure': 10,\n",
       "         'building': 29,\n",
       "         'interfaces': 12,\n",
       "         'tools': 80,\n",
       "         'encourage': 6,\n",
       "         'likely': 15,\n",
       "         'come': 60,\n",
       "         'across': 50,\n",
       "         'design': 32,\n",
       "         'patterns': 18,\n",
       "         'called': 69,\n",
       "         'Model': 9,\n",
       "         'View': 23,\n",
       "         'Controller': 4,\n",
       "         'Presenter': 1,\n",
       "         'ViewModel': 2,\n",
       "         'My': 222,\n",
       "         'has': 320,\n",
       "         'parts': 10,\n",
       "         'What': 746,\n",
       "         'issues': 58,\n",
       "         'address': 29,\n",
       "         'they': 270,\n",
       "         'similar': 67,\n",
       "         'different': 164,\n",
       "         'call': 110,\n",
       "         'shell': 29,\n",
       "         'commands': 33,\n",
       "         'inside': 78,\n",
       "         'program': 81,\n",
       "         'output': 134,\n",
       "         'into': 293,\n",
       "         'disable': 22,\n",
       "         'major': 19,\n",
       "         'browsers': 32,\n",
       "         'Inversion': 2,\n",
       "         'Control': 9,\n",
       "         'IoC': 6,\n",
       "         'quite': 73,\n",
       "         'confusing': 14,\n",
       "         'when': 474,\n",
       "         'first': 158,\n",
       "         'encountered': 8,\n",
       "         'appropriate': 18,\n",
       "         'best': 177,\n",
       "         'calling': 22,\n",
       "         'function': 272,\n",
       "         'given': 72,\n",
       "         'name': 136,\n",
       "         'Python': 250,\n",
       "         'let': 39,\n",
       "         'module': 31,\n",
       "         'whose': 8,\n",
       "         'contents': 25,\n",
       "         'return': 125,\n",
       "         'why': 140,\n",
       "         'don': 314,\n",
       "         'figured': 11,\n",
       "         'define': 32,\n",
       "         'temp': 9,\n",
       "         'returns': 40,\n",
       "         'result': 89,\n",
       "         'm': 892,\n",
       "         'hoping': 18,\n",
       "         'elegant': 20,\n",
       "         'Most': 17,\n",
       "         'degree': 7,\n",
       "         'will': 423,\n",
       "         'certainly': 15,\n",
       "         'Big': 3,\n",
       "         'O': 28,\n",
       "         'stands': 4,\n",
       "         'helps': 12,\n",
       "         'measure': 9,\n",
       "         'efficient': 30,\n",
       "         'algorithm': 41,\n",
       "         'really': 146,\n",
       "         'if': 602,\n",
       "         'category': 5,\n",
       "         'problem': 161,\n",
       "         'trying': 181,\n",
       "         'lays': 1,\n",
       "         'figure': 32,\n",
       "         'possible': 189,\n",
       "         'squeeze': 2,\n",
       "         'extra': 37,\n",
       "         'performance': 66,\n",
       "         '1': 412,\n",
       "         'But': 232,\n",
       "         'curious': 13,\n",
       "         'approximate': 2,\n",
       "         'complexity': 12,\n",
       "         'algorithms': 15,\n",
       "         'overdo': 1,\n",
       "         'premature': 2,\n",
       "         'optimization': 15,\n",
       "         'root': 19,\n",
       "         'all': 538,\n",
       "         'evil': 4,\n",
       "         'without': 186,\n",
       "         'justified': 1,\n",
       "         'cause': 20,\n",
       "         'deserve': 2,\n",
       "         'well': 126,\n",
       "         'built': 41,\n",
       "         'accepted': 15,\n",
       "         'practice': 29,\n",
       "         'length': 35,\n",
       "         'undo': 21,\n",
       "         'changes': 168,\n",
       "         'caused': 6,\n",
       "         'command': 184,\n",
       "         'In': 282,\n",
       "         'feel': 58,\n",
       "         'free': 39,\n",
       "         'other': 307,\n",
       "         'loop': 99,\n",
       "         'difference': 197,\n",
       "         'between': 248,\n",
       "         'break': 29,\n",
       "         'continue': 39,\n",
       "         'means': 54,\n",
       "         'leave': 12,\n",
       "         'structure': 42,\n",
       "         'next': 42,\n",
       "         'iteration': 6,\n",
       "         'Example': 33,\n",
       "         'represents': 10,\n",
       "         'directed': 3,\n",
       "         'graph': 9,\n",
       "         'render': 14,\n",
       "         'dynamically': 12,\n",
       "         'HTML': 87,\n",
       "         'These': 21,\n",
       "         'graphs': 3,\n",
       "         'usually': 46,\n",
       "         'few': 103,\n",
       "         'nodes': 8,\n",
       "         'ten': 2,\n",
       "         'end': 77,\n",
       "         'guess': 26,\n",
       "         'isn': 45,\n",
       "         'going': 86,\n",
       "         'big': 28,\n",
       "         'deal': 20,\n",
       "         'Ideally': 12,\n",
       "         'd': 240,\n",
       "         'hook': 5,\n",
       "         'users': 102,\n",
       "         'tweak': 3,\n",
       "         'layout': 39,\n",
       "         'manually': 32,\n",
       "         'dragging': 2,\n",
       "         'around': 106,\n",
       "         'Note': 52,\n",
       "         'charting': 1,\n",
       "         'library': 50,\n",
       "         'case': 134,\n",
       "         'each': 180,\n",
       "         'And': 126,\n",
       "         'differences': 63,\n",
       "         'designing': 2,\n",
       "         'REST': 22,\n",
       "         'API': 50,\n",
       "         'service': 36,\n",
       "         'established': 4,\n",
       "         'practices': 15,\n",
       "         'dealing': 23,\n",
       "         'security': 12,\n",
       "         'Authentication': 2,\n",
       "         'Authorization': 3,\n",
       "         'Identity': 5,\n",
       "         'Management': 9,\n",
       "         'SOAP': 7,\n",
       "         'WS': 2,\n",
       "         'guide': 19,\n",
       "         'literature': 3,\n",
       "         'exists': 43,\n",
       "         'found': 155,\n",
       "         'less': 63,\n",
       "         'securing': 1,\n",
       "         'endpoints': 2,\n",
       "         'While': 25,\n",
       "         'understand': 143,\n",
       "         'intentionally': 2,\n",
       "         'specifications': 4,\n",
       "         'analogous': 1,\n",
       "         'emerged': 2,\n",
       "         'Any': 56,\n",
       "         'discussion': 21,\n",
       "         'links': 25,\n",
       "         'relevant': 23,\n",
       "         'documents': 9,\n",
       "         'appreciated': 18,\n",
       "         'matters': 7,\n",
       "         'we': 236,\n",
       "         'WCF': 2,\n",
       "         'POX': 1,\n",
       "         'JSON': 55,\n",
       "         'serialized': 2,\n",
       "         'messages': 28,\n",
       "         'our': 74,\n",
       "         'Services': 11,\n",
       "         'v3': 3,\n",
       "         '5': 161,\n",
       "         'Framework': 12,\n",
       "         'Whenever': 7,\n",
       "         'wonder': 12,\n",
       "         'naming': 18,\n",
       "         'item': 55,\n",
       "         'Quite': 3,\n",
       "         'ask': 26,\n",
       "         'myself': 83,\n",
       "         'Should': 31,\n",
       "         'table': 108,\n",
       "         'names': 54,\n",
       "         'plural': 2,\n",
       "         'singular': 7,\n",
       "         'prefix': 13,\n",
       "         'tables': 41,\n",
       "         'columns': 51,\n",
       "         'items': 29,\n",
       "         'Are': 69,\n",
       "         'From': 29,\n",
       "         'see': 228,\n",
       "         'enum': 11,\n",
       "         'exactly': 77,\n",
       "         'attribute': 59,\n",
       "         'Anyone': 9,\n",
       "         'explanation': 25,\n",
       "         'post': 59,\n",
       "         'SP1': 3,\n",
       "         'been': 296,\n",
       "         'released': 6,\n",
       "         'along': 23,\n",
       "         'VS2008': 2,\n",
       "         'access': 77,\n",
       "         'entity': 9,\n",
       "         'framework': 27,\n",
       "         'decide': 10,\n",
       "         'Entity': 7,\n",
       "         'LINQ': 21,\n",
       "         'SQL': 63,\n",
       "         'ORM': 5,\n",
       "         'used': 209,\n",
       "         'Entities': 1,\n",
       "         'brother': 1,\n",
       "         'advantages': 14,\n",
       "         'its': 148,\n",
       "         'came': 32,\n",
       "         'mind': 24,\n",
       "         'after': 120,\n",
       "         'learned': 25,\n",
       "         'developers': 21,\n",
       "         'basics': 4,\n",
       "         'mean': 99,\n",
       "         'declarations': 3,\n",
       "         'conditionals': 2,\n",
       "         'loops': 15,\n",
       "         'operators': 32,\n",
       "         'etc': 100,\n",
       "         'mastered': 1,\n",
       "         'Generics': 1,\n",
       "         'anonymous': 13,\n",
       "         'types': 56,\n",
       "         'lambdas': 6,\n",
       "         'hidden': 19,\n",
       "         'features': 29,\n",
       "         'tricks': 11,\n",
       "         'fans': 1,\n",
       "         'addicts': 1,\n",
       "         'experts': 3,\n",
       "         'barely': 3,\n",
       "         'Here': 119,\n",
       "         'revealed': 2,\n",
       "         'far': 78,\n",
       "         'Keywords': 1,\n",
       "         'Michael': 5,\n",
       "         'Stum': 3,\n",
       "         'statement': 39,\n",
       "         'kokos': 4,\n",
       "         'Mike': 2,\n",
       "         'Stone': 1,\n",
       "         'Ed': 3,\n",
       "         'Swangren': 1,\n",
       "         'improved': 7,\n",
       "         'Rocketpants': 1,\n",
       "         'deathofrats': 1,\n",
       "         'pzycoman': 1,\n",
       "         'blocks': 7,\n",
       "         'AlexCuse': 1,\n",
       "         'Jakub': 2,\n",
       "         'turc': 2,\n",
       "         'Attributes': 2,\n",
       "         'DannySmurf': 2,\n",
       "         'Stu': 1,\n",
       "         'bdukes': 1,\n",
       "         'marxidad': 4,\n",
       "         'Martin': 2,\n",
       "         'Clarke': 2,\n",
       "         'AndrewBurns': 1,\n",
       "         'Syntax': 4,\n",
       "         'coalesce': 1,\n",
       "         'nulls': 4,\n",
       "         'operator': 52,\n",
       "         'Number': 15,\n",
       "         'flaggings': 1,\n",
       "         'Nick': 1,\n",
       "         'Berardi': 1,\n",
       "         'Lars': 1,\n",
       "         'M': 2,\n",
       "         'hlum': 1,\n",
       "         'Implicit': 1,\n",
       "         'generics': 6,\n",
       "         'Keith': 5,\n",
       "         'parameter': 34,\n",
       "         'Auto': 6,\n",
       "         'properties': 54,\n",
       "         'Namespace': 1,\n",
       "         'aliases': 2,\n",
       "         'Verbatim': 1,\n",
       "         'literals': 2,\n",
       "         'Patrick': 1,\n",
       "         'lfoust': 1,\n",
       "         'variablenames': 1,\n",
       "         'Format': 3,\n",
       "         'brackets': 12,\n",
       "         'Portman': 1,\n",
       "         'Property': 3,\n",
       "         'accessor': 1,\n",
       "         'accessibility': 2,\n",
       "         'modifiers': 2,\n",
       "         'xanadont': 1,\n",
       "         'Conditional': 1,\n",
       "         'ternary': 3,\n",
       "         'JasonS': 1,\n",
       "         'Binoj': 1,\n",
       "         'Antony': 1,\n",
       "         'Flory': 1,\n",
       "         'Language': 6,\n",
       "         'Features': 5,\n",
       "         'Nullable': 4,\n",
       "         'Brad': 2,\n",
       "         'Barker': 1,\n",
       "         'Anonymous': 1,\n",
       "         'Judah': 1,\n",
       "         'Himango': 1,\n",
       "         'Object': 17,\n",
       "         'initializers': 1,\n",
       "         'lomaxx': 2,\n",
       "         'strings': 43,\n",
       "         'David': 3,\n",
       "         'Dakota': 1,\n",
       "         'Extension': 1,\n",
       "         'Methods': 5,\n",
       "         'methods': 70,\n",
       "         'Jon': 7,\n",
       "         'Erickson': 1,\n",
       "         'Preprocessor': 1,\n",
       "         'directives': 7,\n",
       "         'John': 16,\n",
       "         'Asbeck': 1,\n",
       "         'pre': 15,\n",
       "         'processor': 6,\n",
       "         'directive': 10,\n",
       "         'Robert': 3,\n",
       "         'Durgin': 1,\n",
       "         'Operator': 12,\n",
       "         'overloading': 4,\n",
       "         'SefBkn': 1,\n",
       "         'inferrence': 1,\n",
       "         'chakrit': 1,\n",
       "         'Boolean': 3,\n",
       "         'taken': 15,\n",
       "         'Rob': 4,\n",
       "         'Gough': 1,\n",
       "         'Pass': 1,\n",
       "         'variable': 121,\n",
       "         'interface': 28,\n",
       "         'boxing': 2,\n",
       "         'Roman': 3,\n",
       "         'Boiko': 2,\n",
       "         'Programmatically': 1,\n",
       "         'declared': 6,\n",
       "         'Static': 3,\n",
       "         'Constructors': 1,\n",
       "         'Chris': 2,\n",
       "         'Easier': 1,\n",
       "         'eyes': 6,\n",
       "         'condensed': 1,\n",
       "         'mapping': 6,\n",
       "         'roosteronacid': 13,\n",
       "         'Zac': 1,\n",
       "         'Bowling': 1,\n",
       "         'Select': 3,\n",
       "         'block': 19,\n",
       "         'text': 179,\n",
       "         'editor': 15,\n",
       "         'Himadri': 1,\n",
       "         'Snippets': 1,\n",
       "         'KiwiBastard': 4,\n",
       "         'IainMH': 1,\n",
       "         'Diago': 1,\n",
       "         'ageektrapped': 1,\n",
       "         'Juan': 1,\n",
       "         'Manuel': 1,\n",
       "         'Properties': 4,\n",
       "         'method': 190,\n",
       "         'Will': 18,\n",
       "         'Dean': 2,\n",
       "         'HasValue': 1,\n",
       "         'Value': 5,\n",
       "         'Rismo': 1,\n",
       "         'Sheehan': 1,\n",
       "         'Tips': 2,\n",
       "         'Tricks': 2,\n",
       "         'Nice': 5,\n",
       "         'event': 43,\n",
       "         'handlers': 7,\n",
       "         'Andreas': 2,\n",
       "         'H': 3,\n",
       "         'R': 26,\n",
       "         'Nilsson': 1,\n",
       "         'Uppercase': 1,\n",
       "         'comparisons': 4,\n",
       "         'Access': 7,\n",
       "         'reflection': 3,\n",
       "         'dp': 4,\n",
       "         'A': 149,\n",
       "         'quick': 19,\n",
       "         'lazily': 1,\n",
       "         'instantiate': 4,\n",
       "         'collection': 18,\n",
       "         'inline': 14,\n",
       "         'functions': 62,\n",
       "         'netmodules': 1,\n",
       "         'LINQBridge': 1,\n",
       "         'Duncan': 1,\n",
       "         'Smart': 1,\n",
       "         'Parallel': 1,\n",
       "         'Extensions': 3,\n",
       "         'Joel': 3,\n",
       "         'Coehoorn': 1,\n",
       "         'preceding': 1,\n",
       "         'five': 8,\n",
       "         'lines': 77,\n",
       "         'matched': 3,\n",
       "         ...})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(' '.join(all_text).split())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5d190a5f1340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab_from_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the documents argument. Try an iterator.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             self.train(\n\u001b[1;32m    405\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \"\"\"\n\u001b[1;32m    728\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 729\u001b[0;31m             documents, self.docvecs, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         report_values = self.vocabulary.prepare_vocab(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m                     logger.warning(\n\u001b[1;32m    811\u001b[0m                         \u001b[0;34m\"Each 'words' should be a list of words (usually unicode strings). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, Doc2VecVocab\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "\n",
    "model = Doc2Vec([all_text[:10]], vector_size=100, min_count=2, epochs=1, verbose=1)\n",
    "\n",
    "model.build_vocab_from_freq(c)\n",
    "model.train(c, total_examples=len(c), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I want to use a track bar to change a form s opacity This is my code When I build the application it gives the following error Cannot implicitly convert type to I tried using and but then the control doesn t work This code worked fine in a past VB NET project',\n",
       "  'Given a representing a person s birthday how do I calculate their age in years',\n",
       "  'Given a specific value how do I display relative time like 2 hours ago 3 days ago a month ago',\n",
       "  'Is there any standard way for a Web Server to be able to determine a user s timezone within a web page Perhaps from an HTTP header or part of the user agent string',\n",
       "  'I often have to sort a dictionary consisting of keys values by value For example I have a hash of words and respective frequencies that I want to order by frequency There is a which is good for a single value say frequency that I want to map it back to the word SortedDictionary orders by key not value Some resort to a custom class but is there a cleaner way',\n",
       "  'Form based authentication for websites We believe that Stack Overflow should not just be a resource for very specific technical questions but also for general guidelines on how to solve variations on common problems Form based authentication for websites should be a fine topic for such an experiment It should include topics such as How to log in How to log out How to remain logged in Managing cookies including recommended settings SSL HTTPS encryption How to store passwords Using secret questions Forgotten username password functionality Use of nonces to prevent cross site request forgeries CSRF OpenID Remember me checkbox Browser autocompletion of usernames and passwords Secret URLs public URL protected by digest Checking password strength E mail validation and much more about form based authentication It should not include things like Roles and authorization HTTP basic authentication Please help us by Suggesting subtopics Submitting good articles about this subject Editing the official answer',\n",
       "  'One may not always know the Type of an object at compile time but may need to create an instance of the Type How do you get a new object instance from a Type',\n",
       "  'Given that is so important as your data set increases in size can someone explain how does indexing work at a level For information on queries to index a field check out How do I index a database column',\n",
       "  'Yes Podcasts those nice little Audiobooks I can listen to on the way to work With the current amount of Podcasts it s like searching a needle in a haystack except that the haystack happens to be the Internet and is filled with too many of these Hot new Gadgets stuff Now even though I am mainly a NET developer nowadays maybe anyone knows some good Podcasts from people regarding the whole software lifecycle Unit Testing Continous Integration Documentation Deployment So what are you guys and gals listening to Please note that the categorizations are somewhat subjective and may not be 100 accurate as many podcasts cover several areas Categorization is made against what is considered the main area General Software Engineering Productivity Stack Overflow inactive but still a good listen TekPub Requires Paid Subscription Software Engineering Radio 43 Folders Perspectives Dr Dobb s now a video feed The Pragmatic Podcast Inactive IT Matters Agile Toolkit Podcast The Stack Trace Inactive Parleys Techzing The Startup Success Podcast Berkeley CS class lectures FLOSS Weekly This Developer s Life NET Visual Studio Microsoft Herding Code Hanselminutes NET Rocks Deep Fried Bytes Alt Net Podcast inactive Polymorphic Podcast inconsistent Sparkling Client The Silverlight Podcast dnrTV Spaghetti Code ASP NET Podcast Channel 9 Radio TFS PowerScripting Podcast The Thirsty Developer Elegant Code inactive ConnectedShow Crafty Coders Coding QA jQuery yayQuery The official jQuery podcast Java Groovy The Java Posse Grails Podcast Java Technology Insider Basement Coders Ruby Rails Railscasts Rails Envy The Ruby on Rails Podcast Rubiverse Ruby5 Web Design JavaScript Ajax WebDevRadio Boagworld The Rissington podcast Ajaxian YUI Theater Unix Linux Mac iPhone Mac Developer Network Hacker Public Radio Linux Outlaws Mac OS Ken LugRadio Linux radio show Inactive The Linux Action Show Linux Kernel Mailing List LKML Summary Podcast Stanford s iPhone programming class Advanced iPhone Development Course Madison Area Technical College WWDC 2010 Session Videos requires Apple Developer registration System Administration Security or Infrastructure RunAs Radio Security Now Crypto Gram Security Podcast Hak5 VMWare VMTN Windows Weekly PaulDotCom Security The Register Semi Coherent Computing FeatherCast General Tech Business Tekzilla This Week in Tech The Guardian Tech Weekly PCMag Radio Podcast Inactive Entrepreneurship Corner Manager Tools Other Misc Podcast Networks IT Conversations Retrobits Podcast No Agenda Netcast Cranky Geeks The Command Line Freelance Radio IBM developerWorks The Register Open Season Drunk and Retired Technometria Sod This Radio4Nerds Hacker Medley',\n",
       "  'Preferred languages C C Java and Ruby I am looking for some helpful books tutorials on how to write your own compiler simply for educational purposes I am most familiar with C C Java and Ruby so I prefer resources that involve one of those three but any good resource is acceptable']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[all_text[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import html\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "def clean_text(x, remove_html=True, other=False):\n",
    "    if remove_html:\n",
    "        x = re.sub(r'<code>[^>]*</code>', '', x)\n",
    "        x = re.sub(r'<[^>]*>', '', x)\n",
    "        x = re.sub(r'[^A-Za-z0-9]', ' ', x)\n",
    "    if other:\n",
    "        x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "            'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "            '<br />', \"\\n\").replace('\\\\\"', '').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "            ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\"',\"'\").replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "    return re1.sub(' ', html.unescape(x).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "DB_NAME = 'StackOverflow.db'\n",
    "\n",
    "start_index = 0\n",
    "# limit = 5000\n",
    "limit = 50\n",
    "last_unix = 0\n",
    "cur_length = limit\n",
    "counter = 0\n",
    "connection = sqlite3.connect(DB_NAME)\n",
    "c = connection.cursor()\n",
    "\n",
    "# while cur_length == limit:\n",
    "#     df = pd.read_sql(\"SELECT comment, title FROM posts WHERE title is NOT NULL LIMIT {}\".format(limit), connection)\n",
    "#     df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7480341\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT comment, title FROM posts WHERE parent_id is NULL and score > 0\", \n",
    "                 connection, chunksize=10000)\n",
    "\n",
    "def preprocess(df, field):\n",
    "    all_text = []\n",
    "    for i, data in enumerate(df):  \n",
    "#         print(i)\n",
    "        all_text.extend([clean_text(i) for i in data[field]])\n",
    "    return all_text\n",
    "\n",
    "all_text = preprocess(df, 'title')\n",
    "print(len(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, vect = compute_tfidf(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf_scores = dict(zip(vect.get_feature_names(), vect.idf_))\n",
    "idf_scores = defaultdict(lambda:0, zip(vect.get_feature_names(), vect.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.605802066295998"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_scores['cool']\n",
    "# avg_word_vectors(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14185559, 0.08583777, 0.09819513, 0.07051642, 0.07526899,\n",
       "       0.06991629, 0.16301519, 0.06954121, 0.13013352, 0.07046131,\n",
       "       0.11755379, 0.17314393, 0.09804197, 0.1647598 , 0.09804197,\n",
       "       0.16862811, 0.13692706, 0.10050308, 0.09584303, 0.14989091,\n",
       "       0.09830537, 0.16662482, 0.09460471, 0.09265912, 0.15983128,\n",
       "       0.09736615, 0.1296375 , 0.06346664, 0.06333943, 0.11294143,\n",
       "       0.13893036, 0.12639903, 0.14109408, 0.05996348, 0.17856848,\n",
       "       0.04762009, 0.14185559, 0.03917769, 0.0904954 , 0.03942107,\n",
       "       0.07703553, 0.11514935, 0.09505124, 0.17079183, 0.13824596,\n",
       "       0.13013352, 0.15205463, 0.09143574, 0.18175239, 0.13446791,\n",
       "       0.10380805, 0.09881659, 0.09881659, 0.1259665 , 0.14035342,\n",
       "       0.15680724, 0.11215783, 0.12512168, 0.17856848, 0.05471944,\n",
       "       0.13893036, 0.15698316, 0.10832387, 0.17856848, 0.04083706,\n",
       "       0.18175239, 0.10540373])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.getrow(0).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(filename):\n",
    "    embeddings = {}\n",
    "    with open(MODEL_PATH/filename, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        embed_list = list(reader)\n",
    "    for line in embed_list:\n",
    "        embeddings[line[0]] = np.asarray(line[1:], dtype=np.float32)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_embeddings('starspace_embedding300.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec_tests(func, embeddings, dim, *args):\n",
    "    if (np.zeros(dim) != func('', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(dim) != func('thereisnosuchword', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (embeddings['word'] != func('word', embeddings, dim, *args)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if ((embeddings['cool'] + embeddings['beans']) / 2 != func('Cool Beans', embeddings, dim, *args)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (embeddings['word'] != func('thereisnosuchword word', embeddings, dim, *args)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic tests are passed.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_to_vec_tests(avg_word_vectors, embeddings, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You should not consider words which embeddings are unknown.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_to_vec_tests(average_tfidf_vectors, embeddings, 300, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "import torch\n",
    "\n",
    "def rank_candidates_pytorch(question, candidates, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    cos = CosineSimilarity(dim=1)\n",
    "    question2vec = question_to_vec(question, embeddings, dim)\n",
    "    candidate2vecs = np.array([question_to_vec(cand, embeddings, dim) for cand in candidates])\n",
    "    output = cos(torch.Tensor(question2vec.reshape(1, -1)).cuda(), torch.Tensor(candidate2vecs).cuda())\n",
    "    output = output.cpu().numpy()\n",
    "    data = [(i, candidates[i]) for i in range(len(output))]   \n",
    "    return [x for _, x in sorted(zip(output, data), key=lambda pair: pair[0], reverse=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    dup_ranks = np.array(dup_ranks)\n",
    "    return len(dup_ranks[dup_ranks <= k]) / len(dup_ranks)\n",
    "\n",
    "def dcg_score(dup_ranks, k):\n",
    "    dup_ranks = np.array(dup_ranks)\n",
    "    N = len(dup_ranks)\n",
    "    dup_ranks = dup_ranks[dup_ranks <= k]\n",
    "    out = np.sum((np.ones_like(dup_ranks)) / (np.log2(1.0 + dup_ranks))) / float(N)\n",
    "    if np.isnan(out): out = 0.0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data\n",
    "\n",
    "validation = read_corpus('data/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_ranking = []\n",
    "for line in validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
