{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Representation and Question Answer Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import html\n",
    "\n",
    "from pathlib import Path\n",
    "MODEL_PATH = Path('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16022817 16022817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['applying opacity form use decimal double value',\n",
       " 'percentage width child element absolutely positioned parent internet explorer 7',\n",
       " 'calculate someones age c#',\n",
       " 'calculate relative time c#',\n",
       " 'determine users timezone',\n",
       " 'difference mathfloor mathtruncate',\n",
       " 'filling dataset datatable linq query result set',\n",
       " 'binary data mysql',\n",
       " 'fastest way get value pi',\n",
       " 'throw error mysql trigger']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "def clean_text(x, remove_html=True, other=False):\n",
    "    if remove_html:\n",
    "        x = re.sub(r'<code>[^>]*</code>', '', x)\n",
    "        x = re.sub(r'<[^>]*>', '', x)\n",
    "        x = re.sub(r'[^A-Za-z0-9]', ' ', x)\n",
    "    if other:\n",
    "        x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "            'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "            '<br />', \"\\n\").replace('\\\\\"', '').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "            ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\"',\"'\").replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "    return re1.sub(' ', html.unescape(x).strip())\n",
    "\n",
    "\n",
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "def clean_title(text, remove_html=False, other=False):\n",
    "    \n",
    "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
    "    \n",
    "    if remove_html:\n",
    "        x = re.sub(r'<code>[^>]*</code>', '', x)\n",
    "        x = re.sub(r'<[^>]*>', '', x)\n",
    "        x = re.sub(r'[^A-Za-z0-9]', ' ', x)\n",
    "    text = text.lower()\n",
    "    text = text.replace('Ï€', 'pi').replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "            'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "            '<br />', \"\\n\").replace('\\\\\"', '').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "            ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\"',\"'\").replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = replace_by_space_re.sub(' ', text)\n",
    "    text = bad_symbols_re.sub('', text)\n",
    "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
    "    return re1.sub(' ', html.unescape(text).strip())\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "DB_NAME = 'StackOverflow.db'\n",
    "\n",
    "connection = sqlite3.connect(DB_NAME)\n",
    "c = connection.cursor() \n",
    "\n",
    "def get_data(column):\n",
    "    df = pd.read_sql(\"SELECT {} FROM posts WHERE parent_id is NULL\".format(column), \n",
    "                 connection, chunksize=10000)\n",
    "    all_text = preprocess(df, 'title')\n",
    "    return all_text\n",
    "    \n",
    "\n",
    "def preprocess(df, field):\n",
    "    comment_id = []\n",
    "    all_text = []\n",
    "    for i, data in enumerate(df):  \n",
    "#         all_text.extend([clean_text(x, remove_html=True) for x in data['title']])\n",
    "        all_text.extend([clean_title(x) for x in data['title']])\n",
    "        comment_id.extend(x for x in data['comment_id'])\n",
    "    return all_text, comment_id\n",
    "\n",
    "\n",
    "all_titles, comment_ids = get_data('comment_id, title')\n",
    "print(len(all_titles), len(all_titles))\n",
    "all_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need to compare them to the COMMENTS as well\n",
    "- Need to link the post ids to the comments to return the top ANSWERS for the question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168402\n"
     ]
    }
   ],
   "source": [
    "# RECOMPUTE with ALL text !!!!!!!!!!!!!!\n",
    "\n",
    "def compute_tfidf(X, X_test=None, save_path=MODEL_PATH/'tf_idf.pkl', load=True, save=False):\n",
    "    \n",
    "    if load:\n",
    "        with open(save_path, mode='rb') as f:\n",
    "            vect = pickle.load(f) \n",
    "    else:\n",
    "        vect = TfidfVectorizer(token_pattern='(\\S+)', min_df=5, max_df=0.9, ngram_range=(1,1))\n",
    "        vect.fit(X)\n",
    "        if save:\n",
    "            # save vect\n",
    "            with open(save_path, mode='wb') as f:\n",
    "                pickle.dump(vect, f)\n",
    "            print('SAVED')\n",
    "\n",
    "    X = vect.transform(X)\n",
    "    if X_test: \n",
    "        X_test = vect.transform(X_test)\n",
    "        return X, X_test, vect   \n",
    "    return X, vect\n",
    "\n",
    "\n",
    "X, vect = compute_tfidf(all_titles, load=True, save=False)\n",
    "idf_scores = defaultdict(lambda:0, zip(vect.get_feature_names(), vect.idf_))\n",
    "print(len(idf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(filename):\n",
    "    embeddings = {}\n",
    "    with open(MODEL_PATH/filename, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        embed_list = list(reader)\n",
    "    for line in embed_list:\n",
    "        embeddings[line[0]] = np.asarray(line[1:], dtype=np.float32)\n",
    "    return embeddings\n",
    "\n",
    "# embeddings = get_embeddings('starspace_embedding300_ngram2.tsv')\n",
    "embeddings = get_embeddings('starspace_embedding100_ngram2.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Approaches\n",
    "- Doc2Vec : you can train your dataset using Doc2Vec and then use the sentence vectors.\n",
    "- Average of Word2Vec vectors : You can just take the average of all the word vectors in a sentence. This average vector will represent your sentence vector.\n",
    "- Average of Word2Vec vectors with TF-IDF : this is one of the best approach which I will recommend. Just take the word vectors and multiply it with their TF-IDF scores. Just take the average and it will represent your sentence vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n",
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "def avg_word_vectors(question, embeddings, dim):\n",
    "    words_embedding = [embeddings[word] for word in question.lower().split() if word in embeddings]\n",
    "    if not words_embedding:\n",
    "        return np.zeros(dim)\n",
    "    words_embedding = np.array(words_embedding).astype(np.float32)\n",
    "    return words_embedding.mean(axis=0)\n",
    "\n",
    "def average_tfidf_vectors(question, embeddings, dim, vect):\n",
    "    # get idf weights\n",
    "    split_question = [word for word in question.lower().split() if word in embeddings]\n",
    "    if not split_question:\n",
    "        return np.zeros(dim).astype(np.float32)\n",
    "    words_embedding = np.zeros((dim, len(split_question))).astype(np.float32)\n",
    "    for i, token in enumerate(split_question):\n",
    "        if token in embeddings:\n",
    "            embed_score = embeddings[token]\n",
    "        else: embed_score = 0\n",
    "        idf_score = idf_scores[token]\n",
    "        # word vectors multiply by their TF-IDF scores\n",
    "        words_embedding[:, i] = embed_score * idf_score    \n",
    "    return words_embedding.mean(axis=1)\n",
    "\n",
    "def question_to_vec_tests(func, embeddings, dim, *args):\n",
    "    if (np.zeros(dim) != func('', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(dim) != func('thereisnosuchword', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (embeddings['word'] != func('word', embeddings, dim, *args)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if ((embeddings['cool'] + embeddings['beans']) / 2 != func('Cool Beans', embeddings, dim, *args)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (embeddings['word'] != func('thereisnosuchword word', embeddings, dim, *args)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\"\n",
    "\n",
    "def question_to_vec_tfidf_tests(func, embeddings, dim, *args):\n",
    "    if (np.zeros(dim) != func('', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(dim) != func('thereisnosuchword', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (embeddings['word'] * idf_scores['word'] != func('word', embeddings, dim, *args)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if (((embeddings['cool'] * idf_scores['cool']) + (embeddings['beans'] * idf_scores['beans'])) / 2 != func('Cool Beans', embeddings, dim, *args)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (embeddings['word'] * idf_scores['word'] != func('thereisnosuchword word', embeddings, dim, *args)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\"\n",
    "\n",
    "print(question_to_vec_tests(avg_word_vectors, embeddings, 100))\n",
    "print(question_to_vec_tfidf_tests(average_tfidf_vectors, embeddings, 100, vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "import torch\n",
    "\n",
    "def rank_candidates(question, candidates, embeddings, dim=300, question_to_vec=avg_word_vectors, topk=5, \n",
    "                    return_score=False, *args, **kwargs):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    cos = CosineSimilarity(dim=1)\n",
    "    question2vec = question_to_vec(question, embeddings, dim, *args, **kwargs)\n",
    "    candidate2vecs = np.array([question_to_vec(cand, embeddings, dim, *args, **kwargs) for cand in candidates])\n",
    "    output = cos(torch.Tensor(question2vec.reshape(1, -1)).cuda(), torch.Tensor(candidate2vecs).cuda())\n",
    "    output = output.cpu().numpy()\n",
    "    data = [(i, candidates[i]) for i in range(len(output))]   \n",
    "    if return_score:\n",
    "        output = [(x, score) for score, x in sorted(zip(output, data), key=lambda pair: pair[0], reverse=True)]\n",
    "    else:\n",
    "        output = [x for _, x in sorted(zip(output, data), key=lambda pair: pair[0], reverse=True)]\n",
    "    if topk: return output[:topk]\n",
    "    else: return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'applying opacity form use decimal double value'), 1.0000001), ((133296, 'use double instead decimal'), 0.6872146), ((2298201, 'double decimal values'), 0.6751053), ((369862, 'decimal double'), 0.6741582), ((1530132, 'convert double c# decimal c++'), 0.65882087)]\n",
      "CPU times: user 57.6 s, sys: 575 ms, total: 58.2 s\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ex = 'While applying opacity to a form should we use a decimal or a double value'\n",
    "print(rank_candidates(ex, all_titles[:2314688], embeddings, 100, average_tfidf_vectors, return_score=True, vect=vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "M = 1\n",
    "efC = 1000\n",
    "num_threads = 4\n",
    "index_time_params = {'indexThreadQty': num_threads, 'efConstruction': efC, 'post' : 0}\n",
    "\n",
    "def create_index(a):\n",
    "    index = nmslib.init(space='cosinesimil')\n",
    "    index.addDataPointBatch(a)\n",
    "    index.createIndex()\n",
    "    return index\n",
    "\n",
    "def get_knns(index, vecs):\n",
    "    return zip(*index.knnQueryBatch(vecs, k=10, num_threads=4))\n",
    "\n",
    "def get_knn(index, vec):\n",
    "    return index.knnQuery(vec, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# candidate2vecs = np.array([average_tfidf_vectors(cand, embeddings, 300, vect) for cand in all_titles[:2314688]])\n",
    "\n",
    "# nms_index = create_index(candidate2vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What s the best way to get speakers for my Users Group',\n",
       " 'Testing for inequality in T SQL',\n",
       " 'SQL query count and group by',\n",
       " 'How do I most elegantly express left join with aggregate SQL as LINQ query',\n",
       " 'How do I use T SQL Group By',\n",
       " 'Can I logically reorder columns in a table',\n",
       " 'Why all the Active Record hate',\n",
       " 'How do I Transform Sql Columns into Rows',\n",
       " 'Access a SQL Server 2005 Express Edition from a network computer',\n",
       " 'Select all columns except one in MySQL']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'How do I calculate someones age in C#?'\n",
    "question2vec = average_tfidf_vectors(question, embeddings, 300, vect)\n",
    "\n",
    "idxs, distances = get_knns(nms_index, [question2vec])\n",
    "# idxs[0]#, distances\n",
    "\n",
    "[all_titles[i] for i in idxs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unpickle(filename):\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         return pickle.load(f)\n",
    "\n",
    "# thread_embeddings_path = MODEL_PATH/'thread_embeddings_by_tags'\n",
    "\n",
    "# tag_path = 'c' + '.pkl'\n",
    "# embeddings_file = thread_embeddings_path/tag_path\n",
    "# ids, vectors = unpickle(embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_path = 'c' + '.bin'\n",
    "# knn_path = MODEL_PATH/'knn_embeddings_path'\n",
    "# filepath = str(knn_path/tag_path)\n",
    "\n",
    "# index = nmslib.init()\n",
    "# index.loadIndex(filepath)\n",
    "# question = 'How do I calculate someones age in C#?'\n",
    "# question2vec = average_tfidf_vectors(question, embeddings, 300, vect)\n",
    "# idxs, distances = index.knnQuery([question2vec], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you access Object properties from within an object method\n",
      "['How would you access Object properties from within an object method', 'Using object property as default for method property', 'Should I provide accessor methods Getter Setters for public protected components on a form', 'Get a new object instance from a Type', 'Adding a Method to an Existing Object Instance', 'Linq to objects select first object', 'How to generate getters and setters in Visual Studio', 'Using in to match an attribute of Python objects in an array', 'User Control Property Designer Properties', 'What is Object Mocking and when do I need it']\n",
      "[ 30 166 610  94 117 737 314  87 858 435]\n"
     ]
    }
   ],
   "source": [
    "i = 30\n",
    "print(all_titles[i])\n",
    "idxs, distances = get_knn(nms_index, average_tfidf_vectors(all_titles[i], embeddings, 300, vect))\n",
    "print([all_titles[i] for i in idxs])\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    dup_ranks = np.array(dup_ranks)\n",
    "    return len(dup_ranks[dup_ranks <= k]) / len(dup_ranks)\n",
    "\n",
    "def dcg_score(dup_ranks, k):\n",
    "    dup_ranks = np.array(dup_ranks)\n",
    "    N = len(dup_ranks)\n",
    "    dup_ranks = dup_ranks[dup_ranks <= k]\n",
    "    out = np.sum((np.ones_like(dup_ranks)) / (np.log2(1.0 + dup_ranks))) / float(N)\n",
    "    if np.isnan(out): out = 0.0\n",
    "    return out\n",
    "\n",
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data\n",
    "\n",
    "def test_embeddings(embeddings, dim, func, *args, **kwargs):\n",
    "    wv_ranking = []\n",
    "    for line in validation:\n",
    "        q, *ex = line\n",
    "        ranks = rank_candidates(q, ex, embeddings, dim, func, topk=None, *args, **kwargs)\n",
    "        wv_ranking.append([r[0] for r in ranks].index(0) + 1)\n",
    "        \n",
    "    for k in [1, 5, 10, 100, 500, 1000]:\n",
    "        print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), \n",
    "                                              k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = read_corpus('data/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.423 | Hits@   1: 0.423\n",
      "DCG@   5: 0.524 | Hits@   5: 0.612\n",
      "DCG@  10: 0.547 | Hits@  10: 0.683\n",
      "DCG@ 100: 0.585 | Hits@ 100: 0.867\n",
      "DCG@ 500: 0.598 | Hits@ 500: 0.966\n",
      "DCG@1000: 0.602 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "test_embeddings(embeddings, 300, avg_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.434 | Hits@   1: 0.434\n",
      "DCG@   5: 0.528 | Hits@   5: 0.610\n",
      "DCG@  10: 0.548 | Hits@  10: 0.670\n",
      "DCG@ 100: 0.583 | Hits@ 100: 0.843\n",
      "DCG@ 500: 0.598 | Hits@ 500: 0.956\n",
      "DCG@1000: 0.602 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "test_embeddings(embeddings, 100, avg_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.453 | Hits@   1: 0.453\n",
      "DCG@   5: 0.548 | Hits@   5: 0.631\n",
      "DCG@  10: 0.567 | Hits@  10: 0.690\n",
      "DCG@ 100: 0.602 | Hits@ 100: 0.861\n",
      "DCG@ 500: 0.616 | Hits@ 500: 0.964\n",
      "DCG@1000: 0.619 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "test_embeddings(embeddings, 300, average_tfidf_vectors, vect=vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.413 | Hits@   1: 0.413\n",
      "DCG@   5: 0.503 | Hits@   5: 0.579\n",
      "DCG@  10: 0.520 | Hits@  10: 0.632\n",
      "DCG@ 100: 0.557 | Hits@ 100: 0.812\n",
      "DCG@ 500: 0.574 | Hits@ 500: 0.946\n",
      "DCG@1000: 0.580 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "test_embeddings(embeddings, 100, average_tfidf_vectors, vect=vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.417 | Hits@   1: 0.417\n",
      "DCG@   5: 0.516 | Hits@   5: 0.605\n",
      "DCG@  10: 0.539 | Hits@  10: 0.677\n",
      "DCG@ 100: 0.578 | Hits@ 100: 0.859\n",
      "DCG@ 500: 0.592 | Hits@ 500: 0.967\n",
      "DCG@1000: 0.595 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# n-gram 2 100 dimension \n",
    "test_embeddings(embeddings, 100, avg_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.441 | Hits@   1: 0.441\n",
      "DCG@   5: 0.533 | Hits@   5: 0.614\n",
      "DCG@  10: 0.554 | Hits@  10: 0.678\n",
      "DCG@ 100: 0.591 | Hits@ 100: 0.854\n",
      "DCG@ 500: 0.605 | Hits@ 500: 0.965\n",
      "DCG@1000: 0.609 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# n-gram 2 100 dimension \n",
    "test_embeddings(embeddings, 100, average_tfidf_vectors, vect=vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK out using [nmslib](https://github.com/nmslib/nmslib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x, y = make_classification(n_classes=5, n_clusters_per_class=5, n_informative=5)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(random_state=100)\n",
    "clf.fit(x, y)\n",
    "preds = clf.predict_proba(x)\n",
    "preds_full = clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 3, 2, 1, 1, 0, 3, 0, 1, 2, 4, 1, 4, 1, 4, 4, 0, 4, 0, 4,\n",
       "       3, 1, 0, 4, 4, 2, 1, 1, 0, 0, 3, 1, 4, 4, 2, 4, 0, 3, 2, 1, 3, 2,\n",
       "       2, 3, 0, 0, 4, 0, 1, 4, 1, 0, 1, 3, 0, 2, 4, 4, 2, 2, 3, 4, 0, 3,\n",
       "       1, 0, 0, 3, 0, 3, 1, 3, 1, 2, 2, 1, 2, 0, 2, 3, 2, 3, 2, 0, 4, 0,\n",
       "       1, 2, 2, 4, 3, 3, 4, 1, 4, 4, 0, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_preds(X, k=3):\n",
    "    preds = clf.predict_proba([X])\n",
    "    return np.argsort(preds)[:,::-1][0][:3]\n",
    "\n",
    "get_top_preds(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [x for _, x in sorted(zip(output, data), key=lambda pair: pair[0], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __iter__(self):\n",
    "        for i, line in enumerate(self.data):\n",
    "            yield TaggedDocument(words=line.split(), tags=['SENT_{}'.format(i)])\n",
    "\n",
    "\n",
    "\n",
    "labeled_sent = LabeledLineSentence(all_titles[:100000])\n",
    "model = Doc2Vec(vector_size=300, window=10, min_count=1, workers=4, alpha=0.025, min_alpha=0.025, epochs=10) \n",
    "model.build_vocab(labeled_sent)\n",
    "model.train(labeled_sent, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_ranking = []\n",
    "    for line in validation:\n",
    "        q, *ex = line\n",
    "        ranks = rank_candidates(q, ex, embeddings, dim, func, topk=None, *args, **kwargs)\n",
    "        wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SENT_37495', 0.5060877799987793),\n",
       " ('SENT_92897', 0.4604107737541199),\n",
       " ('SENT_85994', 0.4344367980957031),\n",
       " ('SENT_79654', 0.4209355413913727),\n",
       " ('SENT_51531', 0.4206792116165161),\n",
       " ('SENT_95806', 0.4194100499153137),\n",
       " ('SENT_86052', 0.4170324206352234),\n",
       " ('SENT_79209', 0.41459929943084717),\n",
       " ('SENT_4856', 0.41097453236579895),\n",
       " ('SENT_80020', 0.40738117694854736)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = 'random state'\n",
    "ex_infer = model.infer_vector(ex.split())\n",
    "model.docvecs.most_similar([ex_infer], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "n_similarity() missing 2 required positional arguments: 'ds1' and 'ds2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6dc49ebbfea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: n_similarity() missing 2 required positional arguments: 'ds1' and 'ds2'"
     ]
    }
   ],
   "source": [
    "model.docvecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Entity Framework vs LINQ to SQL'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list(labeled_sent)[855].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['while',\n",
       " 'applying',\n",
       " 'opacity',\n",
       " 'to',\n",
       " 'form',\n",
       " 'should',\n",
       " 'we',\n",
       " 'use',\n",
       " 'decimal',\n",
       " 'or',\n",
       " 'double',\n",
       " 'value']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labeled_sent)[0].words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "0 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-a0661682b958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minferred_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minferred_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in list"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(all_text)):\n",
    "    inferred_vector = model.infer_vector(list(labeled_sent)[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import html\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "def clean_text(x, remove_html=True, other=False):\n",
    "    if remove_html:\n",
    "        x = re.sub(r'<code>[^>]*</code>', '', x)\n",
    "        x = re.sub(r'<[^>]*>', '', x)\n",
    "        x = re.sub(r'[^A-Za-z0-9]', ' ', x)\n",
    "    if other:\n",
    "        x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "            'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "            '<br />', \"\\n\").replace('\\\\\"', '').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "            ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\"',\"'\").replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "    return re1.sub(' ', html.unescape(x).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "DB_NAME = 'StackOverflow.db'\n",
    "\n",
    "start_index = 0\n",
    "# limit = 5000\n",
    "limit = 50\n",
    "last_unix = 0\n",
    "cur_length = limit\n",
    "counter = 0\n",
    "connection = sqlite3.connect(DB_NAME)\n",
    "c = connection.cursor()\n",
    "\n",
    "# while cur_length == limit:\n",
    "#     df = pd.read_sql(\"SELECT comment, title FROM posts WHERE title is NOT NULL LIMIT {}\".format(limit), connection)\n",
    "#     df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16022817\n",
      "CPU times: user 1min 44s, sys: 20.2 s, total: 2min 5s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_sql(\"SELECT comment, title FROM posts WHERE parent_id is NULL\", \n",
    "                 connection, chunksize=10000)\n",
    "\n",
    "def preprocess(df, field):\n",
    "    all_text = []\n",
    "    for i, data in enumerate(df):  \n",
    "#         print(i)\n",
    "        all_text.extend([clean_text(i) for i in data[field]])\n",
    "    return all_text\n",
    "\n",
    "all_text = preprocess(df, 'title')\n",
    "print(len(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;I want to use a track-bar to change a form'...</td>\n",
       "      <td>While applying opacity to a form, should we us...</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>557</td>\n",
       "      <td>c# winforms type-conversion decimal opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Given a &lt;code&gt;DateTime&lt;/code&gt; representing ...</td>\n",
       "      <td>How do I calculate someone's age in C#?</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>1745</td>\n",
       "      <td>c# .net datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Given a specific &lt;code&gt;DateTime&lt;/code&gt; valu...</td>\n",
       "      <td>Calculate relative time in C#</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>1317</td>\n",
       "      <td>c# datetime time datediff relative-time-span</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Is there any standard way for a Web Server ...</td>\n",
       "      <td>Determine a User's Timezone</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>529</td>\n",
       "      <td>javascript html browser timezone timezoneoffset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;I often have to sort a dictionary, consisti...</td>\n",
       "      <td>How do you sort a dictionary by value?</td>\n",
       "      <td>2008-08-02</td>\n",
       "      <td>671</td>\n",
       "      <td>c# sorting dictionary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id parent_id                                            comment  \\\n",
       "0           4      None  <p>I want to use a track-bar to change a form'...   \n",
       "1           9      None  <p>Given a <code>DateTime</code> representing ...   \n",
       "2          11      None  <p>Given a specific <code>DateTime</code> valu...   \n",
       "3          13      None  <p>Is there any standard way for a Web Server ...   \n",
       "4         289      None  <p>I often have to sort a dictionary, consisti...   \n",
       "\n",
       "                                               title        date  score  \\\n",
       "0  While applying opacity to a form, should we us...  2008-07-31    557   \n",
       "1            How do I calculate someone's age in C#?  2008-07-31   1745   \n",
       "2                      Calculate relative time in C#  2008-07-31   1317   \n",
       "3                        Determine a User's Timezone  2008-08-01    529   \n",
       "4             How do you sort a dictionary by value?  2008-08-02    671   \n",
       "\n",
       "                                              tags  \n",
       "0      c# winforms type-conversion decimal opacity  \n",
       "1                                 c# .net datetime  \n",
       "2     c# datetime time datediff relative-time-span  \n",
       "3  javascript html browser timezone timezoneoffset  \n",
       "4                            c# sorting dictionary  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM posts WHERE parent_id is NULL and score > 500 LIMIT 10\", \n",
    "                 connection)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, vect = compute_tfidf(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf_scores = dict(zip(vect.get_feature_names(), vect.idf_))\n",
    "idf_scores = defaultdict(lambda:0, zip(vect.get_feature_names(), vect.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.605802066295998"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_scores['cool']\n",
    "# avg_word_vectors(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14185559, 0.08583777, 0.09819513, 0.07051642, 0.07526899,\n",
       "       0.06991629, 0.16301519, 0.06954121, 0.13013352, 0.07046131,\n",
       "       0.11755379, 0.17314393, 0.09804197, 0.1647598 , 0.09804197,\n",
       "       0.16862811, 0.13692706, 0.10050308, 0.09584303, 0.14989091,\n",
       "       0.09830537, 0.16662482, 0.09460471, 0.09265912, 0.15983128,\n",
       "       0.09736615, 0.1296375 , 0.06346664, 0.06333943, 0.11294143,\n",
       "       0.13893036, 0.12639903, 0.14109408, 0.05996348, 0.17856848,\n",
       "       0.04762009, 0.14185559, 0.03917769, 0.0904954 , 0.03942107,\n",
       "       0.07703553, 0.11514935, 0.09505124, 0.17079183, 0.13824596,\n",
       "       0.13013352, 0.15205463, 0.09143574, 0.18175239, 0.13446791,\n",
       "       0.10380805, 0.09881659, 0.09881659, 0.1259665 , 0.14035342,\n",
       "       0.15680724, 0.11215783, 0.12512168, 0.17856848, 0.05471944,\n",
       "       0.13893036, 0.15698316, 0.10832387, 0.17856848, 0.04083706,\n",
       "       0.18175239, 0.10540373])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.getrow(0).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(filename):\n",
    "    embeddings = {}\n",
    "    with open(MODEL_PATH/filename, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        embed_list = list(reader)\n",
    "    for line in embed_list:\n",
    "        embeddings[line[0]] = np.asarray(line[1:], dtype=np.float32)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_embeddings('starspace_embedding100.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec_tests(func, embeddings, dim, *args):\n",
    "    if (np.zeros(dim) != func('', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(dim) != func('thereisnosuchword', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (embeddings['word'] != func('word', embeddings, dim, *args)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if ((embeddings['cool'] + embeddings['beans']) / 2 != func('Cool Beans', embeddings, dim, *args)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (embeddings['word'] != func('thereisnosuchword word', embeddings, dim, *args)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\"\n",
    "\n",
    "def question_to_vec_tfidf_tests(func, embeddings, dim, *args):\n",
    "    if (np.zeros(dim) != func('', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(dim) != func('thereisnosuchword', embeddings, dim, *args)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (embeddings['word'] * idf_scores['word'] != func('word', embeddings, dim, *args)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if (((embeddings['cool'] * idf_scores['cool']) + (embeddings['beans'] * idf_scores['beans'])) / 2 != func('Cool Beans', embeddings, dim, *args)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (embeddings['word'] * idf_scores['word'] != func('thereisnosuchword word', embeddings, dim, *args)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic tests are passed.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_to_vec_tests(avg_word_vectors, embeddings, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic tests are passed.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_to_vec_tests(avg_word_vectors, embeddings, 100)\n",
    "question_to_vec_tfidf_tests(average_tfidf_vectors, embeddings, 100, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tfidf_vectors(question, embeddings, dim, vect):\n",
    "    # get idf weights\n",
    "    split_question = [word for word in question.lower().split() if word in embeddings]\n",
    "    if not split_question:\n",
    "        return np.zeros(dim).astype(np.float32)\n",
    "    words_embedding = np.zeros((dim, len(split_question))).astype(np.float32)\n",
    "    for i, token in enumerate(split_question):\n",
    "        if token in embeddings:\n",
    "            embed_score = embeddings[token]\n",
    "        else: embed_score = 0\n",
    "        idf_score = idf_scores[token]\n",
    "        # word vectors multiply by their TF-IDF scores\n",
    "        words_embedding[:, i] = embed_score * idf_score    \n",
    "    return words_embedding.mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33523113,  0.25927806, -0.75544304, -0.3199052 , -0.28468618,\n",
       "       -0.03379241,  0.08405037, -0.19328661, -0.3096007 ,  0.19111453],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_tfidf_vectors('word', embeddings, dim=300, vect=vect)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33523113,  0.25927806, -0.75544304, -0.3199052 , -0.28468618,\n",
       "       -0.03379241,  0.08405037, -0.19328661, -0.3096007 ,  0.19111453],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_tfidf_vectors('word thereisnosuchword', embeddings, dim=300, vect=vect)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_tfidf_vectors('thereisnosuchword', embeddings, dim=300, vect=vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "import torch\n",
    "\n",
    "def rank_candidates(question, candidates, embeddings, dim=300, topk=5, question_to_vec=avg_word_vectors, *args, **kwargs):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    cos = CosineSimilarity(dim=1)\n",
    "    question2vec = question_to_vec(question, embeddings, dim, *args, **kwargs)\n",
    "    candidate2vecs = np.array([question_to_vec(cand, embeddings, dim, *args, **kwargs) for cand in candidates])\n",
    "    output = cos(torch.Tensor(question2vec.reshape(1, -1)).cuda(), torch.Tensor(candidate2vecs).cuda())\n",
    "    output = output.cpu().numpy()\n",
    "    data = [(i, candidates[i]) for i in range(len(output))]   \n",
    "    output = [x for _, x in sorted(zip(output, data), key=lambda pair: pair[0], reverse=True)]\n",
    "    if topk: return output[:topk]\n",
    "    else: return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    dup_ranks = np.array(dup_ranks)\n",
    "    return len(dup_ranks[dup_ranks <= k]) / len(dup_ranks)\n",
    "\n",
    "def dcg_score(dup_ranks, k):\n",
    "    dup_ranks = np.array(dup_ranks)\n",
    "    N = len(dup_ranks)\n",
    "    dup_ranks = dup_ranks[dup_ranks <= k]\n",
    "    out = np.sum((np.ones_like(dup_ranks)) / (np.log2(1.0 + dup_ranks))) / float(N)\n",
    "    if np.isnan(out): out = 0.0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data\n",
    "\n",
    "validation = read_corpus('data/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_ranking = []\n",
    "for line in validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings, 100, avg_word_vectors)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.434 | Hits@   1: 0.434\n",
      "DCG@   5: 0.528 | Hits@   5: 0.610\n",
      "DCG@  10: 0.548 | Hits@  10: 0.670\n",
      "DCG@ 100: 0.583 | Hits@ 100: 0.843\n",
      "DCG@ 500: 0.598 | Hits@ 500: 0.956\n",
      "DCG@1000: 0.602 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# avg_word_vectors 100\n",
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), \n",
    "                                              k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.441 | Hits@   1: 0.441\n",
      "DCG@   5: 0.540 | Hits@   5: 0.624\n",
      "DCG@  10: 0.560 | Hits@  10: 0.686\n",
      "DCG@ 100: 0.593 | Hits@ 100: 0.846\n",
      "DCG@ 500: 0.607 | Hits@ 500: 0.959\n",
      "DCG@1000: 0.611 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# avg_word_vectors 300\n",
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), \n",
    "                                              k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.248 | Hits@   1: 0.248\n",
      "DCG@   5: 0.332 | Hits@   5: 0.408\n",
      "DCG@  10: 0.354 | Hits@  10: 0.473\n",
      "DCG@ 100: 0.393 | Hits@ 100: 0.666\n",
      "DCG@ 500: 0.419 | Hits@ 500: 0.873\n",
      "DCG@1000: 0.432 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# average_tfidf_vectors 100\n",
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), \n",
    "                                              k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.244 | Hits@   1: 0.244\n",
      "DCG@   5: 0.328 | Hits@   5: 0.405\n",
      "DCG@  10: 0.351 | Hits@  10: 0.477\n",
      "DCG@ 100: 0.391 | Hits@ 100: 0.671\n",
      "DCG@ 500: 0.417 | Hits@ 500: 0.874\n",
      "DCG@1000: 0.430 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "# average_tfidf_vectors\n",
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), \n",
    "                                              k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244507981/work/torch/lib/THC/generated/../generic/THCTensorMathPointwise.cu:367",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-196-4a6a8355c287>\u001b[0m in \u001b[0;36mrank_candidates\u001b[0;34m(question, candidates, embeddings, dim, topk, question_to_vec, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mquestion2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcandidate2vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate2vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/distance.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(x1, x2, dim, eps)\u001b[0m\n\u001b[1;32m   1637\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \"\"\"\n\u001b[0;32m-> 1639\u001b[0;31m     \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0m__rmul__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244507981/work/torch/lib/THC/generated/../generic/THCTensorMathPointwise.cu:367"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = 'Given a representing a person s birthday how do I calculate their age in years'\n",
    "\n",
    "rank_candidates(question, all_text[:1000], embeddings, 100, avg_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need to run tag classifier "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
